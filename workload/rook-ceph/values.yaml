rook-ceph-cluster:
  operatorNamespace: rook-ceph-operator
  configOverride: |
    [global]
    mon_allow_pool_delete = true
    osd_max_backfills = 3
    osd_recovery_max_active = 3
    mon_osd_down_out_interval = 600
  toolbox:
    enabled: true
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 10m
        memory: 128Mi
  monitoring:
    enabled: true
    createPrometheusRules: false
  cephClusterSpec:
    dashboard:
      enabled: true
      port: 8443
      ssl: false
    resources:
      mgr:
        limits:
          cpu: 1000m
          memory: 1Gi
        requests:
          cpu: 10m
          memory: 512Mi
      mon:
        limits:
          cpu: 2000m
          memory: 2Gi
        requests:
          cpu: 10m
          memory: 1Gi
      osd:
        limits:
          cpu: 2000m
          memory: 2Gi
        requests:
          cpu: 10m
          memory: 2Gi
      prepareosd:
        limits:
          cpu: 500m
          memory: 400Mi
        requests:
          cpu: 100m
          memory: 50Mi
      mgr-sidecar:
        limits:
          cpu: 500m
          memory: 100Mi
        requests:
          cpu: 10m
          memory: 50Mi
      crashcollector:
        limits:
          cpu: 500m
          memory: 60Mi
        requests:
          cpu: 10m
          memory: 60Mi
      logcollector:
        limits:
          cpu: 500m
          memory: 1Gi
        requests:
          cpu: 10m
          memory: 50Mi
      cleanup:
        limits:
          cpu: 500m
          memory: 1Gi
        requests:
          cpu: 50m
          memory: 100Mi
    removeOSDsIfOutAndSafeToRemove: true
    storage:
      useAllNodes: true
      useAllDevices: true
  ingress:
    dashboard:
      ingressClassName: nginx
      annotations:
        cert-manager.io/cluster-issuer: letsencrypt-route53-prod
      host:
        name: &host ceph.homelab.linhng98.com
        path: /
      tls:
        - secretName: rook-ceph-tls
          hosts:
            - *host
  cephBlockPools:
    - name: ceph-blockpool
      spec:
        failureDomain: host
        replicated:
          size: 2
      storageClass:
        enabled: true
        name: ceph-block
        isDefault: true
        reclaimPolicy: Delete
        allowVolumeExpansion: true
        mountOptions: []
        parameters:
          imageFormat: '2'
          imageFeatures: layering
          csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/provisioner-secret-namespace: '{{ .Release.Namespace }}'
          csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/controller-expand-secret-namespace: '{{ .Release.Namespace }}'
          csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
          csi.storage.k8s.io/node-stage-secret-namespace: '{{ .Release.Namespace }}'
          csi.storage.k8s.io/fstype: ext4
  cephFileSystems:
    - name: ceph-filesystem
      spec:
        metadataPool:
          replicated:
            size: 2
        dataPools:
          - failureDomain: host
            replicated:
              size: 2
            name: data0
        metadataServer:
          activeCount: 1
          activeStandby: true
          resources:
            limits:
              cpu: 2000m
              memory: 4Gi
            requests:
              cpu: 50m
              memory: 1Gi
          priorityClassName: system-cluster-critical
      storageClass:
        enabled: true
        isDefault: false
        name: ceph-filesystem
        pool: data0
        reclaimPolicy: Delete
        allowVolumeExpansion: true
        mountOptions: []
        parameters:
          csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
          csi.storage.k8s.io/provisioner-secret-namespace: '{{ .Release.Namespace }}'
          csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
          csi.storage.k8s.io/controller-expand-secret-namespace: '{{ .Release.Namespace }}'
          csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
          csi.storage.k8s.io/node-stage-secret-namespace: '{{ .Release.Namespace }}'
          csi.storage.k8s.io/fstype: ext4
  cephObjectStores:
    - name: ceph-objectstore
      # see https://github.com/rook/rook/blob/master/Documentation/CRDs/Object-Storage/ceph-object-store-crd.md#object-store-settings for available configuration
      spec:
        metadataPool:
          failureDomain: host
          replicated:
            size: 2
        dataPool:
          failureDomain: host
          erasureCoded:
            dataChunks: 2
            codingChunks: 1
        preservePoolsOnDelete: false
        gateway:
          port: 80
          instances: 2
          priorityClassName: system-cluster-critical
      storageClass:
        enabled: true
        name: ceph-bucket
        reclaimPolicy: Delete
        parameters:
          region: ap-northeast-1
